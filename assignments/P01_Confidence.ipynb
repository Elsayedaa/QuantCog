{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Confidence\n",
    "## Quantified Cognition\n",
    "### Psychology 5332\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: *Your Name Here*\n",
    "# User ID: *Your ID Here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Upon completion of this assignment, the student will demonstrate the ability to:\n",
    "\n",
    "1. Modify LBA to include confidence\n",
    "2. Fit the model to speed--accuracy data\n",
    "3. Produce distributions confidence for the different conditions\n",
    "4. Evaluate model predicted results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "- The goal of this assignment is to augment the Linear Ballistic Accumulator (LBA) model to generate confidence in addition to choices and response times. You will then test whether the model generates confidence values that make sense for the speed--accuracy trade-off data. \n",
    "\n",
    "- You will perform this assignment by writing code in *this notebook* (***after making a copy and renaming it to have your userid in the title --- e.g., P01_Confidence_mst3k***).\n",
    "\n",
    "- In addition to this notebook, you will need to download the data from the same directory on GitHub. The file is decision_data.csv.\n",
    "\n",
    "- ***When you are done, save this notebook as HTML (`File -> Download as -> HTML`) and upload it to the matching assignment on UVACollab.***\n",
    "\n",
    "## HINTS\n",
    "\n",
    "- Be sure to comment your code\n",
    "- I have provided cells with general instructions for what they should contain.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBA Confidence\n",
    "\n",
    "Extend LBA to include generation of a confidence value in addition to the choice and reaction time it already produces. One method of achieving this (though I'm open to other approaches as long as you justify them) is to assume that confidence is directly proportional to the level of activation for the accumulator with the winning choice relative to the sum of all the accumulator activations at that time. In the literature this is called the Relative Balence of Evidence.\n",
    "\n",
    "Intuitively, this approach makes some sense. If the selected choice has a high level of activation relative to the non-selected choice, then the confidence will be high (close to 1.0). On the other hand, if there is strong evidence for both choices and one just barely wins out over the other, then the ratio of the winning choice to all choices will be closer to .5 (for the two-choice case).\n",
    "\n",
    "To test whether this model is, indeed, making predictions that make sense, pick the variant of the LBA model that fit best to the speed--accuracy trade-off decision data (the one that allowed threshold to change between conditions) and perform the fit again with this new model. Even though you are not fitting to confidence, we can simulate the model with the best-fitting parameters and generate a distribution of confidence values for the speed condition and confidence values for the accuracy condition.\n",
    "\n",
    "Here are some questions to answer in your write-up:\n",
    "\n",
    "- Are people more confident in their correct answers in the accuracy condition than in the speeded condition? Does your result make sense?\n",
    "- Are the confidence values different for correct and incorrect answers?\n",
    "- What would happen to the confidence values (on average) if you added in a third option? (You could even take your best-fitting params and simply add in a third option to the inputs at either low or high levels of input to see what would happen.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "\n",
    "from RunDEMC.density import kdensity\n",
    "from RunDEMC import Model, Param, dists\n",
    "from RunDEMC import DE, calc_bpic, joint_plot\n",
    "from RunDEMC.io import arviz_dict\n",
    "from RunDEMC.pda import PDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>rt</th>\n",
       "      <th>cond</th>\n",
       "      <th>log_rt</th>\n",
       "      <th>rt_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>-0.737308</td>\n",
       "      <td>0.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>-0.843970</td>\n",
       "      <td>0.4300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4486</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>-0.801624</td>\n",
       "      <td>0.4486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>Speed</td>\n",
       "      <td>-0.918543</td>\n",
       "      <td>0.3991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4393</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>-0.822573</td>\n",
       "      <td>0.4393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   correct      rt      cond    log_rt  rt_acc\n",
       "3        1  0.4784  Accuracy -0.737308  0.4784\n",
       "4        1  0.4300  Accuracy -0.843970  0.4300\n",
       "5        1  0.4486  Accuracy -0.801624  0.4486\n",
       "6        1  0.3991     Speed -0.918543  0.3991\n",
       "8        1  0.4393  Accuracy -0.822573  0.4393"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the data\n",
    "dat = pd.read_csv('decision_data.csv', index_col=0)\n",
    "dat = dat[dat.cond != 'Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for the LBA model (from class)\n",
    "\n",
    "The next few cells instantiate the LBA model and also fit a variant where we allow the threshold ($b$) to change between conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lba_sim(I=(1.0,1.5), A=.1, S=1.0, b=1.0, num_sims=1000,\n",
    "            max_time=2., t0=0.0, **kwargs):\n",
    "    # set drift rate from inputs\n",
    "    dr = np.squeeze(np.atleast_1d(I))\n",
    "    \n",
    "    # set the number of choices\n",
    "    nc = len(dr)\n",
    "    \n",
    "    # pick starting points\n",
    "    k = np.random.uniform(0.,A,(num_sims,nc))\n",
    "    \n",
    "    # pick drifts\n",
    "    # must make sure at least one d is greater than zero for each sim\n",
    "    d = np.random.normal(dr,S,(num_sims,nc))\n",
    "    \n",
    "    ## see where there are none above zero\n",
    "    #ind = np.all(d<=0.0,axis=1)\n",
    "    #while np.any(ind):\n",
    "    #    d[ind,:] = np.random.normal(dr,S,(ind.sum(),nc))\n",
    "    #    ind = np.all(d<=0.0,axis=1)\n",
    "\n",
    "    # clip it to avoid divide by zeros\n",
    "    d[d<=0.0] = np.finfo(dr.dtype).eps\n",
    "\n",
    "    # calc the times for each\n",
    "    t = (b-k)/d\n",
    "\n",
    "    # see the earliest for each resp\n",
    "    inds = t.argmin(1)\n",
    "    times = t.take(inds+np.arange(t.shape[0])*t.shape[1])\n",
    "\n",
    "    # process into choices\n",
    "    times += t0\n",
    "\n",
    "    # get valid responses\n",
    "    resp_ind = times < (max_time)\n",
    "    inds[~resp_ind] = -1\n",
    "    times[~resp_ind] = -1\n",
    "    \n",
    "    # make a dataframe \n",
    "    # NOTE: you should add in returning confidence values here\n",
    "    return pd.DataFrame({'correct': inds, 'rt': times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model with a threshold change between conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract best fitting params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate distributions of confidence values for speed and accuracy conditions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots to see how those distributions compare to one another\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write your short answer here to the questions listed above:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
